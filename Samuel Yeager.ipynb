{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import time\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will build a classification model that will predict whether a reddit post, with only the title and text content provided, is in the World of Warcraft (WoW) subreddit or the Final Fantasy XIV (FFXIV) subreddit.  \n",
    "I am approaching the problem from the perspective of part of the marketing team at Square Enix, the publisher of FFXIV.  With this model, we can predict uncover language that our players use frequently, so we can better craft our marketing to appeal to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need is to use pushshift to grab our posts.  I built a function to grab 100 posts from every month from each subreddit, going back to the subreddit's founding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posts_getter(subreddit):\n",
    "    #using https://www.epochconverter.com/ I converted the current date \n",
    "    #and dates of the FFXI subreddit's founding (ffxiv is younger, so this way we'll have a more equal split)\n",
    "    current_epoch = 1611872155\n",
    "    founding_epoch = 1454019344\n",
    "    one_month_in_seconds = 2628288\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    posts = []\n",
    "    #sets the founding_epoch variable depending on what subreddit was passed.  If the subreddit isn't within the scope of this project, it returns an error.  \n",
    "    #With some fancy webscraping I could probably work it out to get any subreddit, but for now I'm leaving it to these two.\n",
    "    #if subreddit == 'wow':\n",
    "        #founding_epoch = wow_founding_epoch\n",
    "    #elif subreddit == 'ffxiv':\n",
    "        #founding_epoch = ffxiv_founding_epoch\n",
    "   # else:\n",
    "        #print('sorry, I have no data for that subreddit')\n",
    "    #iterates, month by month, from the founding of the subreddit to january 28, 2021, pulling 100 posts every month.\n",
    "    #this spread of time helps ensure that there are no duplicate posts, and also gives us a very wide view of each subreddit\n",
    "    time.sleep(15)\n",
    "    for month in range(founding_epoch, current_epoch, one_month_in_seconds):\n",
    "        res = requests.get(url, {'subreddit': subreddit, 'size': 100, 'before': month})\n",
    "        try:\n",
    "            data = res.json()\n",
    "            posts.extend(data['data'])\n",
    "        except:\n",
    "            pass\n",
    "    return posts\n",
    "#gets the posts\n",
    "ffxiv_posts = posts_getter('ffxiv')\n",
    "wow_posts = posts_getter('wow')\n",
    "#turns those posts into a dataframe\n",
    "ffxiv_df = pd.DataFrame(ffxiv_posts)\n",
    "wow_df = pd.DataFrame(wow_posts)\n",
    "print('ffxiv shape is',ffxiv_df.shape)\n",
    "print(wow_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10893, 100)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wow_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow_df.loc[lambda wow_df: wow_df['selftext'].isna() == True] = wow_df.loc[lambda wow_df: wow_df['selftext'].isna() == True].fillna('notatextpost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wow_df['selftext'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffxiv_df.loc[lambda ffxiv_df: ffxiv_df['selftext'].isna() == True] = ffxiv_df.loc[lambda fxiv_df: ffxiv_df['selftext'].isna() == True].fillna('notatextpost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffxiv_df['selftext'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ffxiv_df, wow_df], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, I'd leave the below uncommented in order to save the dataframe.  However, I'm commenting it out to make sure I'm calling the same dataframe that I created on Friday, January 29th.  This keeps my modeling consistent day to day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('./concatenated_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bramblepatch/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (25,72,74,77,78,79,81,84,85,86,94,95,96,100,103,104) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./concatenated_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm turning my subreddit column into a numeric, and renaming it to reflect that.  I could have used get_dummies here as well, but decided to use this method as it makes certain that FFXIV is my positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'].replace(['ffxiv','wow'],[1,0], inplace = True)\n",
    "df.rename(columns = {'subreddit':'is_on_ffxiv'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I separate the three columns I really need: our features and our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['selftext','title', 'is_on_ffxiv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selftext       5478\n",
       "title             0\n",
       "is_on_ffxiv       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[lambda df: df['selftext'].isna() == True] = df.loc[lambda df: df['selftext'].isna() == True].fillna('notatextpost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14738, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step is to get some distributions, of post-word-count and post-length.  Refer to prevous labs for code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in order to build my model, I use the Snowball Stemmer to get stems of every word in my text posts and my titles (ignoring the stop words so that I can save on computational expense, since they'll just get dropped later). This will help save on computational expenses later on as well, since I'll have fewer features from my CountVectorizer.  \n",
    "I then use CountVectorizer to split up all my self-text and titles.   This results in a very large dataset, but that is to be expected given the wide variety of language that can be used on reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_selftext_tokens(row):\n",
    "    text = row['selftext']\n",
    "    tokens = word_tokenize(text)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "def identify_title_tokens(row):\n",
    "    text = row['title']\n",
    "    tokens = word_tokenize(text)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['self_text_words'] = df.apply(identify_selftext_tokens, axis = 1)\n",
    "df['title_words'] = df.apply(identify_title_tokens, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           [notatextpost]\n",
       "1                                                [removed]\n",
       "2                                                [removed]\n",
       "3                                           [notatextpost]\n",
       "4                                           [notatextpost]\n",
       "                               ...                        \n",
       "14733                                       [notatextpost]\n",
       "14734    [Hey, all, just, started, an, alt, as, a, sham...\n",
       "14735                                       [notatextpost]\n",
       "14736                                       [notatextpost]\n",
       "14737    [I, have, almost, cleared, raid, bosses, and, ...\n",
       "Name: self_text_words, Length: 14738, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['self_text_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [Post, your, favourite, screenshots]\n",
       "1             [Old, Player, Thinking, about, Coming, Back]\n",
       "2                        [New, player, Recruit, a, friend]\n",
       "3        [Have, drawn, anything, in, like, a, decade, P...\n",
       "4        [What, are, the, chances, the, fate, of, this,...\n",
       "                               ...                        \n",
       "14733    [This, is, why, TC, is, fun, as, a, Destro, Wa...\n",
       "14734               [Pro, and, con, of, elemental, shaman]\n",
       "14735    [Twisting, corridors, is, so, hard, for, warri...\n",
       "14736    [When, Flayedwing, Toxin, gives, you, a, third...\n",
       "14737                               [Loot, is, a, problem]\n",
       "Name: title_words, Length: 14738, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed_self_text'] = df['self_text_words'].apply(lambda x: [SnowballStemmer(\"english\", ignore_stopwords=True).stem(y) for y in x])\n",
    "df['stemmed_title'] = df['title_words'].apply(lambda x: [SnowballStemmer(\"english\", ignore_stopwords=True).stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14723    [is, it, all, class, except, energi, base, spe...\n",
       "14724                                       [notatextpost]\n",
       "14725    [okay, i, was, in, war, mode, when, i, was, do...\n",
       "14726                                              [delet]\n",
       "14727    [just, spent, two, hour, on, it, just, to, be,...\n",
       "14728    [so, i, just, start, play, wow, for, real, abo...\n",
       "14729                                      [i, salut, you]\n",
       "14730                                       [notatextpost]\n",
       "14731                                       [notatextpost]\n",
       "14732    [so, i, know, i, want, to, dps, and, i, m, awa...\n",
       "14733                                       [notatextpost]\n",
       "14734    [hey, all, just, start, an, alt, as, a, shaman...\n",
       "14735                                       [notatextpost]\n",
       "14736                                       [notatextpost]\n",
       "14737    [i, have, almost, clear, raid, boss, and, i, h...\n",
       "Name: stemmed_self_text, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemmed_self_text'].tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#let's also get columns for the length of each post and title\n",
    "df['self_text_len'] = df['selftext'].apply(lambda x: len(x.split()))\n",
    "df['title_len'] = df['title'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[lambda df: df['selftext'] == '[removed]'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>is_on_ffxiv</th>\n",
       "      <th>self_text_words</th>\n",
       "      <th>title_words</th>\n",
       "      <th>stemmed_self_text</th>\n",
       "      <th>stemmed_title</th>\n",
       "      <th>self_text_len</th>\n",
       "      <th>title_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notatextpost</td>\n",
       "      <td>Post your favourite screenshots?</td>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[Post, your, favourite, screenshots]</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[post, your, favourit, screenshot]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notatextpost</td>\n",
       "      <td>Haven't drawn anything in like a decade. Picke...</td>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[Have, drawn, anything, in, like, a, decade, P...</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[have, drawn, anyth, in, like, a, decad, pick,...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notatextpost</td>\n",
       "      <td>What are the chances the fate of this NPC gets...</td>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[What, are, the, chances, the, fate, of, this,...</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[what, are, the, chanc, the, fate, of, this, n...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>So a few weeks ago there was a new survey done...</td>\n",
       "      <td>FFXIV survey, realm pop..etc (looking for)</td>\n",
       "      <td>1</td>\n",
       "      <td>[So, a, few, weeks, ago, there, was, a, new, s...</td>\n",
       "      <td>[FFXIV, survey, realm, pop, etc, looking, for]</td>\n",
       "      <td>[so, a, few, week, ago, there, was, a, new, su...</td>\n",
       "      <td>[ffxiv, survey, realm, pop, etc, look, for]</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>notatextpost</td>\n",
       "      <td>Drew my Miquo'te PLD and Lalafell SMN</td>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[Drew, my, PLD, and, Lalafell, SMN]</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[drew, my, pld, and, lalafel, smn]</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  \\\n",
       "0                                       notatextpost   \n",
       "3                                       notatextpost   \n",
       "4                                       notatextpost   \n",
       "5  So a few weeks ago there was a new survey done...   \n",
       "6                                       notatextpost   \n",
       "\n",
       "                                               title  is_on_ffxiv  \\\n",
       "0                   Post your favourite screenshots?            1   \n",
       "3  Haven't drawn anything in like a decade. Picke...            1   \n",
       "4  What are the chances the fate of this NPC gets...            1   \n",
       "5         FFXIV survey, realm pop..etc (looking for)            1   \n",
       "6              Drew my Miquo'te PLD and Lalafell SMN            1   \n",
       "\n",
       "                                     self_text_words  \\\n",
       "0                                     [notatextpost]   \n",
       "3                                     [notatextpost]   \n",
       "4                                     [notatextpost]   \n",
       "5  [So, a, few, weeks, ago, there, was, a, new, s...   \n",
       "6                                     [notatextpost]   \n",
       "\n",
       "                                         title_words  \\\n",
       "0               [Post, your, favourite, screenshots]   \n",
       "3  [Have, drawn, anything, in, like, a, decade, P...   \n",
       "4  [What, are, the, chances, the, fate, of, this,...   \n",
       "5     [FFXIV, survey, realm, pop, etc, looking, for]   \n",
       "6                [Drew, my, PLD, and, Lalafell, SMN]   \n",
       "\n",
       "                                   stemmed_self_text  \\\n",
       "0                                     [notatextpost]   \n",
       "3                                     [notatextpost]   \n",
       "4                                     [notatextpost]   \n",
       "5  [so, a, few, week, ago, there, was, a, new, su...   \n",
       "6                                     [notatextpost]   \n",
       "\n",
       "                                       stemmed_title  self_text_len  title_len  \n",
       "0                 [post, your, favourit, screenshot]              1          4  \n",
       "3  [have, drawn, anyth, in, like, a, decad, pick,...              1         21  \n",
       "4  [what, are, the, chanc, the, fate, of, this, n...              1         13  \n",
       "5        [ffxiv, survey, realm, pop, etc, look, for]             49          6  \n",
       "6                 [drew, my, pld, and, lalafel, smn]              1          7  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns = ['selftext','title','self_text_words','title_words'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_on_ffxiv</th>\n",
       "      <th>stemmed_self_text</th>\n",
       "      <th>stemmed_title</th>\n",
       "      <th>self_text_len</th>\n",
       "      <th>title_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[post, your, favourit, screenshot]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[have, drawn, anyth, in, like, a, decad, pick,...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[what, are, the, chanc, the, fate, of, this, n...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>[so, a, few, week, ago, there, was, a, new, su...</td>\n",
       "      <td>[ffxiv, survey, realm, pop, etc, look, for]</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>[notatextpost]</td>\n",
       "      <td>[drew, my, pld, and, lalafel, smn]</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_on_ffxiv                                  stemmed_self_text  \\\n",
       "0            1                                     [notatextpost]   \n",
       "3            1                                     [notatextpost]   \n",
       "4            1                                     [notatextpost]   \n",
       "5            1  [so, a, few, week, ago, there, was, a, new, su...   \n",
       "6            1                                     [notatextpost]   \n",
       "\n",
       "                                       stemmed_title  self_text_len  title_len  \n",
       "0                 [post, your, favourit, screenshot]              1          4  \n",
       "3  [have, drawn, anyth, in, like, a, decad, pick,...              1         21  \n",
       "4  [what, are, the, chanc, the, fate, of, this, n...              1         13  \n",
       "5        [ffxiv, survey, realm, pop, etc, look, for]             49          6  \n",
       "6                 [drew, my, pld, and, lalafel, smn]              1          7  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./stemmed_and_cleaned_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./stemmed_and_cleaned_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the Count Vectorized self text column\n",
    "self_text_cove = CountVectorizer(stop_words = 'english')\n",
    "self_text_cove.fit(df['stemmed_self_text'])\n",
    "self_text_words = pd.DataFrame(self_text_cove.transform(df['stemmed_self_text']).todense(),columns = self_text_cove.get_feature_names())\n",
    "#creates the Count Vectorized title column\n",
    "title_cove = CountVectorizer(stop_words = 'english')\n",
    "title_cove.fit(_df['stemmed_title'])\n",
    "title_words = pd.DataFrame(title_cove.transform(df['stemmed_title']).todense(),columns = title_cove.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cove_df = pd.concat([title_words, self_text_words, df.drop(columns = ['stemmed_self_text','stemmed_title'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14738, 39534)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cove_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000g</th>\n",
       "      <th>000th</th>\n",
       "      <th>00100</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>...</th>\n",
       "      <th>紅蓮の反乱</th>\n",
       "      <th>紅蓮の戦乱</th>\n",
       "      <th>織田さんがアラミゴの方とクガネまで</th>\n",
       "      <th>英雄よ</th>\n",
       "      <th>蒼天の旅路</th>\n",
       "      <th>蒼天の神話</th>\n",
       "      <th>難易度は侵攻編零式ぐらい</th>\n",
       "      <th>須藤氏が物騒なことをブツブツ言いながら企画していたのですさまじそう</th>\n",
       "      <th>라그나로스</th>\n",
       "      <th>is_on_ffxiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39534 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000g  000th  00100  00am  00pm  01  02  03  ...  紅蓮の反乱  紅蓮の戦乱  \\\n",
       "0   0    0     0      0      0     0     0   0   0   0  ...      0      0   \n",
       "1   0    0     0      0      0     0     0   0   0   0  ...      0      0   \n",
       "2   0    0     0      0      0     0     0   0   0   0  ...      0      0   \n",
       "3   0    0     0      0      0     0     0   0   0   0  ...      0      0   \n",
       "4   0    0     0      0      0     0     0   0   0   0  ...      0      0   \n",
       "\n",
       "   織田さんがアラミゴの方とクガネまで  英雄よ  蒼天の旅路  蒼天の神話  難易度は侵攻編零式ぐらい  \\\n",
       "0                  0    0      0      0             0   \n",
       "1                  0    0      0      0             0   \n",
       "2                  0    0      0      0             0   \n",
       "3                  0    0      0      0             0   \n",
       "4                  0    0      0      0             0   \n",
       "\n",
       "   須藤氏が物騒なことをブツブツ言いながら企画していたのですさまじそう  라그나로스  is_on_ffxiv  \n",
       "0                                  0      0            1  \n",
       "1                                  0      0            1  \n",
       "2                                  0      0            1  \n",
       "3                                  0      0            1  \n",
       "4                                  0      0            1  \n",
       "\n",
       "[5 rows x 39534 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cove_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the most common words across both subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_on_ffxiv     6100\n",
       "notatextpost    5496\n",
       "just            4250\n",
       "like            3307\n",
       "game            2841\n",
       "time            2359\n",
       "ve              2252\n",
       "amp             2205\n",
       "com             2186\n",
       "know            2111\n",
       "new             1957\n",
       "don             1901\n",
       "really          1764\n",
       "https           1720\n",
       "people          1702\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cove_df.sum(axis = 0).sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see ignore the first two values (those are placeholders for what subreddit it's on, and whether the post has any self-text or not.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see that same list for each subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "notatextpost    3553\n",
       "just            2409\n",
       "like            1930\n",
       "wow             1512\n",
       "time            1335\n",
       "game            1301\n",
       "know            1233\n",
       "ve              1210\n",
       "new             1115\n",
       "don             1099\n",
       "people          1038\n",
       "com             1030\n",
       "really          1024\n",
       "play            1006\n",
       "level            993\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cove_df[cove_df['is_on_ffxiv'] == 0].sum(axis = 0).sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_on_ffxiv     6100\n",
       "notatextpost    1943\n",
       "just            1841\n",
       "amp             1548\n",
       "game            1540\n",
       "like            1377\n",
       "com             1156\n",
       "ve              1042\n",
       "https           1037\n",
       "time            1024\n",
       "ffxiv            904\n",
       "know             878\n",
       "new              842\n",
       "don              802\n",
       "really           740\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cove_df[cove_df['is_on_ffxiv'] == 1].sum(axis = 0).sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some distributions!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cove_df.drop(columns = 'is_on_ffxiv')\n",
    "y = cove_df['is_on_ffxiv']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41389605102456234"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline!\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra_fo = RandomForestClassifier()\n",
    "ra_fo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988238487288519\n",
      "0.8534599728629579\n"
     ]
    }
   ],
   "source": [
    "print(ra_fo.score(X_train, y_train))\n",
    "print(ra_fo.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well!  Sure looks like our Random Forest model is quite over fit.  Nonetheless, that testing score is much, much better than our baseline.  So perhaps we can live with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees = ExtraTreesClassifier()\n",
    "extra_trees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988238487288519\n",
      "0.8583446404341927\n"
     ]
    }
   ],
   "source": [
    "print(extra_trees.score(X_train, y_train))\n",
    "print(extra_trees.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, Extra Trees is overly fit, but it's better than our Random Forest, so maybe that's the one we'll take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bramblepatch/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9764769745770379\n",
      "0.8667571234735414\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.score(X_train, y_train))\n",
    "print(log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a surprise!  Of the three, logistic regression has the smallest margin between testing and training, and it performs the best as well.  Let's run with that one into production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
